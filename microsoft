import torch
import torch.nn as nn
import numpy as np
import librosa


class Light(nn.Module):
    def __init__(self, ):
        """
        Several notes:
        1, pay attention to the order of kernel_size and padding_size
        2, the padding is done before the conv, and you cannot do it in the conv
        3, the hidden_size of GRU is the output size of it, dimension must be 3, and sequence dims is dim=1. If set batch_first=True
        4, the channel_num is the initializing parameter for PReLU
        5, the nn.Linear just connects the last dim of tensor, so swap your dimension properly


        """
        super().__init__()
        self.conv = [nn.Conv2d(in_channels=int(2**(i-1)*16),
                               out_channels=2**i *16,
                               kernel_size=(3, 2),
                               stride=(2, 1),
                               bias=False) for i in range(4)]
        self.conv[0]=nn.Conv2d(in_channels=1,
                               out_channels=16,
                               kernel_size=(3, 2),
                               stride=(2, 1),
                               bias=False)
        self.pad=nn.ZeroPad2d(padding=(1,1,1,0))
        self.flat=nn.Flatten(start_dim=1,end_dim=2)
        self.gru=nn.GRU(input_size=512,hidden_size=512,num_layers=1,bias=True,batch_first=True,)
        self.fc1=nn.Linear(512,256)
        self.fc2=nn.Linear(256,2)# change to 1 if you only estimate one feature
        self.actP = [nn.PReLU(2**i*16) for i in range(4)]
        self.actP1=nn.PReLU(256)
        self.actS = nn.Sigmoid()
        self.actT = nn.Tanh()

    def forward(self, input_data):
        # 10s的语音，32ms窗，16ms shift
        x=0
        for i in range(4):
            if i==0:
                x = self.pad(input_data)
            else:
                x = self.pad(x)
            x=self.conv[i](x)
            x=self.actP[i](x)
        x=self.flat(x)
        x = torch.swapdims(x, 1, 2)
        print(x.shape)
        x,_=self.gru(x)
        x=self.actT(x)# 不确定是sigmoid还是tanh
        x=self.fc1(x)
        x = torch.swapdims(x, 1, 2)
        x = self.actP1(x)
        x = torch.swapdims(x, 1, 2)
        x=self.fc2(x)
        x=self.actS(x)
        return x


t=10
sr=16000
audio=np.random.random([t*sr,])
win_t= 32 / 1000
hop_t= 16 / 1000

melS=librosa.feature.mfcc(y=audio, sr=sr, win_length=int(win_t * sr), hop_length=int(hop_t * sr), n_mfcc=64, fmin=0, fmax=8000)
stft=torch.Tensor(melS)
stft=torch.unsqueeze(stft,0)
stft=torch.unsqueeze(stft,0)
model=Light()
out=model(stft)
print(out.shape)
